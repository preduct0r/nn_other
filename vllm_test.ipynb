{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes # For guessing MIME type\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the API key and base URL to your vLLM server\n",
    "openai_api_key = \"EMPTY\"  # vLLM typically doesn't require an API key by default\n",
    "openai_api_base = \"http://localhost:7555/v1\" # Default vLLM server address\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "with open(\"prompts/general_ocr_prompt.txt\") as f:\n",
    "    ocr_prompt= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm serve /home/ubuntu/models/Qwen/Qwen2.5-VL-32B-Instruct-AWQ --port 7555 --quantization awq --dtype float16 --allowed-local-media-path /home/ubuntu/ocr/vllm/benchmark/jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"/home/ubuntu/models/Qwen/Qwen2.5-VL-32B-Instruct-AWQ\",\"object\":\"model\",\"created\":1747912126,\"owned_by\":\"vllm\",\"root\":\"/home/ubuntu/models/Qwen/Qwen2.5-VL-32B-Instruct-AWQ\",\"parent\":null,\"max_model_len\":128000,\"permission\":[{\"id\":\"modelperm-3e0c57d7a9294c19b9f15a80638c6137\",\"object\":\"model_permission\",\"created\":1747912126,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":false,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:7555/v1/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Act as an OCR assistant. Analyze the provided <|image|> image and:\\n1. Identify and transcribe all visible text in the image exactly as it appears.\\n2. Preserve the original line breaks, spacing, and formatting from the image.\\n3. Output only the transcribed text, line by line, without adding any commentary or explanations or special characters.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr(file_path):\n",
    "    # Example for chat completions API (if supported by the model)\n",
    "    try:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": \"file://\" + str(file_path)}},\n",
    "                    {\"type\": \"text\", \"text\": ocr_prompt}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=\"/home/ubuntu/models/Qwen/Qwen2.5-VL-32B-Instruct-AWQ\", # Specify the model loaded on your vLLM server\n",
    "            messages=messages\n",
    "        )\n",
    "        print(\"Chat completion result:\", chat_response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with chat completions: {e}\")\n",
    "        print(\"Note: Some models may not support the 'system' role or the chat API.\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred with chat completions: Error code: 400 - {'object': 'error', 'message': 'The file path /home/den/Documents/Nornikel/vllm/benchmark/original/document_000/page_1.jpg must be a subpath of `--allowed-local-media-path` /home/ubuntu/ocr/vllm/benchmark/jpg.', 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
      "Note: Some models may not support the 'system' role or the chat API.\n"
     ]
    }
   ],
   "source": [
    "get_ocr(\"/home/ubuntu/ocr/vllm/benchmark/jpg/1_page_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination_folder = Path(\"/home/ubuntu/ocr/vllm/benchmark/renamed\")\n",
    "# destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for i, file_path in enumerate(Path(\"/home/ubuntu/ocr/vllm/benchmark/original\").glob(\"*\")):\n",
    "#     new_name = f\"document_{i:03d}.pdf\"\n",
    "#     new_path = destination_folder / new_name\n",
    "\n",
    "#     # Move the file to the destination folder with the new name\n",
    "#     file_path.rename(new_path)\n",
    "#     print(f\"Moved: {file_path.name} â†’ {new_name}\")\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu-73",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
